Article_ID,Title,Title_link,Image,Date,Summary,Content,Field1
200,Apple sparks Palestinian flag emoji controversy,https://www.bbc.com/news/technology-68778830,https://www.bbc.com/bbcx/grey-placeholder.png,21 hrs ago,"iPhone users noticed a Palestinian flag emoji is being suggested when users type ""Jerusalem.""","Apple has been criticised after the Palestinian flag emoji was automatically suggested to iPhone users who type ""Jerusalem."" Both Israel and the Palestinians hold competing claims to the ancient city. TV presenter Rachel Riley, who is Jewish, noted on social media that national flags were not suggested for other capitals. Apple has told the BBC that the change - which followed a recent software update - was not intentional. The issue will be remedied in a future software update, Apple says, but it is not known how rapidly this will happen. Writing on X (formerly Twitter), Ms Riley demanded that Apple explain what had happened. ""Showing double standards with respect to Israel is a form of antisemitism"", she argued. The issue, according to Apple, relates to a feature called predictive emoji. iPhones can suggest emojis when words are typed in messages, and other apps. The notes accompanying the latest iOS update say that it includes ""new emojis."" The status of Jerusalem is one of the thorniest disputes in the conflict between Israel and the Palestinians. Israel sees the whole of Jerusalem as its eternal, undivided capital, while Palestinians claim the eastern part as the capital of their hoped-for future state. East Jerusalem, along with the West Bank and Gaza Strip, were captured by Israel from Jordan and Egypt in a war in 1967, and have since been viewed internationally as occupied Palestinian territory. This is not the first time a big tech company has found itself embroiled in the bitter dispute between Israel and the Palestinians. Last year rival tech giant Meta had to apologise after a bug resulted in it adding ""terrorist"" to the biographies of some Instagram users describing themselves as Palestinian. Meta said it fixed a problem ""that briefly caused inappropriate Arabic translations"" in some of its products. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," TV presenter Rachel Riley, who is Jewish, noted on social media that national flags were not suggested for other capitals. The issue will be remedied in a future software update, Apple says, but it is not known how rapidly this will happen. Writing on X (formerly Twitter), Ms Riley demanded that Apple explain what had happened. Israel sees the whole of Jerusalem as its eternal, undivided capital, while Palestinians claim the eastern part as the capital of their hoped-for future state. East Jerusalem, along with the West Bank and Gaza Strip, were captured by Israel from Jordan and Egypt in a war in 1967, and have since been viewed internationally as occupied Palestinian territory."
201,TikTok to take on Instagram with photo app,https://www.bbc.com/news/articles/cge8j2dyg1qo,https://ichef.bbci.co.uk/news/480/cpsprodpb/2b99/live/2a40ebf0-f66d-11ee-848c-914039e5f405.jpg.webp,2 days ago,"Some TikTok users have received notifications about a new app for photo posts ""coming soon"".","TikTok is to take on social media rival, Instagram, by launching a photo-sharing app. The company said it was working on a ""dedicated space"" for images and text. Some users have received notifications saying their photo posts will be shared to a new ""TikTok Notes"" app unless they opt out. It is the latest example of social media firms imitating each others' products - including Instagram launching Reels, a TikTok-like video tool, in 2020. “The copycat phenomenon runs rampant across social media platforms"", Mike Proulx, a research director at analysis firm Forrester, told the BBC. When done well copycat features ""pay off"", he added, giving the example of when Instagram copied Snapchat with its ""Stories"" feature. However, he pointed out a similar move by Twitter ended in failure, so there was no guarantee of success. Instagram's focus on making Reels more central to app has previously frustrated some users. Kim Kardashian and Kylie Jenner were among those who shared a petition calling out changes to the platform that seemed to promote Reels over other features of the app in 2022. Instagram U-turned on the changes after the backlash. TikTok says it has not finalised the design of the Notes app, nor has it confirmed a release date. But notifications received by some users suggest the app will let users upload or share photo posts - which are currently a feature of the TikTok app and let people post a series of images with sounds and filters. Screenshots of the notification showed a toggle on the notifications allowing TikTok users to opt out of having their photo posts shared to the app. Social media consultant Matt Navarra said a text or photo app might be a space where the majority of TikTok users who “lurk”, rather than post, would engage more. But he said he did not think another photo-sharing app was something social media users were “desperate” for. “We have plenty of them, so I don’t think there’s that demand out there necessarily,” he said. It comes at a difficult time for the company, with the US passing legislation that could see TikTok banned unless its Chinese owner sells it within six months of passing its law. ""Launching Notes as a separate app would be a departure in strategy for TikTok, which has previously incorporated new features directly into the core app, but it makes sense given the current regulatory and consumer scrutiny,"" said Jasmine Enberg, principal social media analyst at Insider Intelligence. ""There are few places left where it doesn’t have a stronghold, and photo-sharing is one,"" she added. Mike Proulx suggested the best way forward for TikTok might be to copy what Meta did with its Twitter rival, Threads, where it leaned heavily on the existing Instagram user base. ""But like Threads, the key will be creating a compelling enough experience to get them to stick around TikTok Notes beyond the initial curiosity factor,"" he added. “When social media features all start to become ubiquitous, what differentiates one social media platform from another narrows. It comes down to community, user experience, and, yes, algorithms.” Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," TikTok is to take on social media rival, Instagram, by launching a photo-sharing app. It is the latest example of social media firms imitating each others' products - including Instagram launching Reels, a TikTok-like video tool, in 2020. “The copycat phenomenon runs rampant across social media platforms"", Mike Proulx, a research director at analysis firm Forrester, told the BBC. Social media consultant Matt Navarra said a text or photo app might be a space where the majority of TikTok users who “lurk”, rather than post, would engage more. ""Launching Notes as a separate app would be a departure in strategy for TikTok, which has previously incorporated new features directly into the core app, but it makes sense given the current regulatory and consumer scrutiny,"" said Jasmine Enberg, principal social media analyst at Insider Intelligence."
202,Tesla to settle over fatal Autopilot crash,https://www.bbc.com/news/articles/c14kggkr4vro,https://ichef.bbci.co.uk/news/480/cpsprodpb/9583/live/2ba1e280-f620-11ee-a927-bde4164a22fa.jpg.webp,2 days ago,"The trial, brought by the family of Apple engineer Walter Huang, was scheduled to begin this week.","Electric car giant Tesla has agreed to settle a lawsuit over a crash in 2018 which killed Apple engineer Walter Huang after his Model X, operating on Autopilot, collided with a highway barrier. The case, brought by Mr Huang's family, was scheduled to begin in the California Superior Court this week. If the trial had gone ahead, it would have brought increased scrutiny of the firm's Autopilot and Full Self-Driving technology. The terms of the settlement were not disclosed and reports have said the deal still needs to be approved by a judge. Tesla did not immediately respond to a BBC request for comment. Before the settlement, Tesla argued that Mr Huang had misused the system because he was playing a video game just before the accident. The firm has previously won trials in California by arguing that drivers involved had not followed its instructions to maintain attention while using the system. The electric vehicle (EV) maker faces a series of lawsuits over crashes related to the alleged use of its driver-assistant technology. The US National Highway Traffic Safety Administration has also been investigating some accidents involving Autopilot. For many years, Tesla has promised to produce an autonomous car but has yet to launch one. On Friday, Mr Musk said the company plans to unveil a self-driving robotaxi in August. The settlement with Mr Huang's family comes at a time when the company is battling weakening sales. Deliveries slid sharply in the first three months of this year as Tesla grappled with a fire at its European factory, global shipping disruption and growing competition. Tesla has cut prices repeatedly in response to increased competition from rivals such as BYD but demand in key markets like China has fallen. Tesla's shares have lost almost a third of their value since the start of this year. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," Electric car giant Tesla has agreed to settle a lawsuit over a crash in 2018 which killed Apple engineer Walter Huang after his Model X, operating on Autopilot, collided with a highway barrier. The case, brought by Mr Huang's family, was scheduled to begin in the California Superior Court this week. If the trial had gone ahead, it would have brought increased scrutiny of the firm's Autopilot and Full Self-Driving technology. Before the settlement, Tesla argued that Mr Huang had misused the system because he was playing a video game just before the accident. Deliveries slid sharply in the first three months of this year as Tesla grappled with a fire at its European factory, global shipping disruption and growing competition."
203,X gives free blue ticks to its most popular users,https://www.bbc.com/news/technology-68718291,https://ichef.bbci.co.uk/news/480/cpsprodpb/EB06/production/_133066106_mediaitem133066104.jpg.webp,7 days ago,"The site formerly known as Twitter is giving premium access to those with more than 2,500 verified followers.","X, formerly Twitter, is giving blue ticks to its most ""influential"" users in a significant change of policy. Those with more than 2,500 verified followers - people already paying for X Premium - have been given premium features for free. As well as the blue tick, the users will see fewer adverts on X. The social media platform also announced it was clearing bots so people may notice follower numbers decreasing. Blue ticks were originally a way to verify users were who they claimed to be, but they became a paid-for feature after Elon Musk purchased the site. However, according to messages received by people who have been given the features, it is now being given out without cost if a person is an ""influential member of the community"". Premium users also see their tweets ranked higher when replying to others, and it enables them to apply for revenue sharing from adverts on the site. Meanwhile, people with more than 5,000 verified followers have been given free access to Premium+, which removes almost all adverts and ranks their tweets even higher when replying to another person. It comes after Mr Musk announced the feature in late March. Before X was bought by Mr Musk, the blue tick was a badge of verification given for free by the platform. It was originally used as a tool of authentication, designed to help stop fake accounts and the spread of misinformation. The blue tick was once seen as a marker of a person's authoritativeness on the site, as only a few people could become verified, such as celebrities, government workers and journalists. Mr Musk disliked this system, which he criticised as creating a split between ""lords and peasants"". Under the billionaire, the blue tick instead became a symbol showing that an account had subscribed to X Premium - previously called Twitter Blue - with a verification process attached to that payment. But now it has become a combination of the two - with a person simply seen as prominent if they are followed by enough people with a checkmark of their own. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," X, formerly Twitter, is giving blue ticks to its most ""influential"" users in a significant change of policy. Those with more than 2,500 verified followers - people already paying for X Premium - have been given premium features for free. Blue ticks were originally a way to verify users were who they claimed to be, but they became a paid-for feature after Elon Musk purchased the site. Premium users also see their tweets ranked higher when replying to others, and it enables them to apply for revenue sharing from adverts on the site. Meanwhile, people with more than 5,000 verified followers have been given free access to Premium+, which removes almost all adverts and ranks their tweets even higher when replying to another person. Before X was bought by Mr Musk, the blue tick was a badge of verification given for free by the platform."
204,Google using AI to create search answers in UK trial,https://www.bbc.com/news/technology-68730138,https://ichef.bbci.co.uk/news/480/cpsprodpb/4EC6/production/_133066102_83aea83b-b4f2-4949-80ca-093e5f322ee0.jpg.webp,7 days ago,Some users will get AI-generated 'overviews' in their Google search results when they ask questions.,"Google has begun trialling search answers written by artificial intelligence (AI) in the UK, after the feature was tested in the US last year. Initially only a small proportion of logged-in UK users will see an AI-generated ""overview"" at the top of some search results. While Google is the most popular search engine, Microsoft's rival Bing already integrates its Copilot AI. But some publishers worry AI answers may reduce visits to their sites. They fear longer chatbot-style responses will satisfy users' curiosity without having to visit their websites, while AI answers will also contain fewer links and ads. The ""Search Generative Experience"" - as Google dubs the feature - has been available for nearly a year in the US, but only to users who signed up via Google Labs. It said the UK experiment will involve a ""small slice"" of UK search traffic, selected from logged-in users. It comes as a front-page report in the Financial Times suggested that the firm was considering offering subscriptions for some premium AI search features in the future. Google denied it was ""working on or considering an ad-free search experience"". Hema Budaraju, who helps drive Google's generative AI efforts in search, told the BBC its new search results will still display links and ads. She said it was a ""priority"" to continue to send traffic to creators, and claimed AI-powered search results were ""actually showing more links to a wider range of sources"". The ""proof was in the pudding"", she said, adding that so far users were clicking on an increased range of sources too. The AI-generated ""overview"" will be shown only in response to certain queries, where current trials have suggested they were helpful. Ms Budaraju said a search for ""how to get marks off painted walls"" is one example that people have found useful. But Google is aware of the risk, common to AI systems, that they can sometimes generate content that is harmful, offensive, display racial or gender bias, or factually wrong. Ms Budaraju said the tech giant wanted to maintain ""information quality"", and it would ""put in a lot of care and attention to do this in a responsible way"". As a result, she said Google chose to make answers less fluent and more constrained, focusing instead on accuracy. For example, it is not generating AI answers to all queries, particularly where there aren't sufficient high quality sources of information. Users can send feedback if they encounter problems with the results - and Google is clear this is an experiment. ""We will find issues of bias and safety,"" she said, ""but the commitment is to find [these] and then invest in making it better"". The firm says US users have responded positively so far, but if the trial is successful and AI generated search answers are eventually used by billions of people, that may bring further challenges. For example, researchers have pointed to the large amounts of electricity required to power the computing that powers big AI systems. That is energy use that comes at an environmental price. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," Google has begun trialling search answers written by artificial intelligence (AI) in the UK, after the feature was tested in the US last year. While Google is the most popular search engine, Microsoft's rival Bing already integrates its Copilot AI. They fear longer chatbot-style responses will satisfy users' curiosity without having to visit their websites, while AI answers will also contain fewer links and ads. The ""Search Generative Experience"" - as Google dubs the feature - has been available for nearly a year in the US, but only to users who signed up via Google Labs. It said the UK experiment will involve a ""small slice"" of UK search traffic, selected from logged-in users. Hema Budaraju, who helps drive Google's generative AI efforts in search, told the BBC its new search results will still display links and ads."
205,Ukraine gives award to vigilantes for Russia hacks,https://www.bbc.com/news/technology-68722542,https://ichef.bbci.co.uk/news/480/cpsprodpb/11298/production/_133069207_0dc66f46-2a9b-49ec-9daf-3f1c14cd5cb3.jpg.webp,8 days ago,The foreign hackers had stolen data from Russian military firms and hacked cameras to spy on troops.,"A team of vigilante hackers carrying out cyber-attacks against Russia has been sent awards of gratitude by Ukraine's military. The team, One Fist, has stolen data from Russian military firms and hacked cameras to spy on troops. The certificates are a controversial sign of how modern warfare is shifting. Concerns have been raised about the practice of states encouraging civilian hackers. One of the hackers called ""Voltage"" has been co-ordinating hacks from his home in the US. His real name is Kristopher Kortright and he is an IT worker from Michigan. The 53-year-old told the BBC he is delighted his efforts for Ukraine have been officially recognised with a certificate of gratitude. One Fist is made up of hackers from eight different countries including the UK, US and Poland. They have collectively launched dozens of cyber-attacks - celebrating each one on social media. The certificates were sent to them all for ""a significant contribution to the development and maintenance of vital activities of the military"". They were signed by the commander of the Airborne Assault Forces of Ukraine. Ukraine's Ministry of Defence did not respond to the BBC's request for comment. Since the start of the conflict, Ukraine has controversially been encouraging volunteer hackers to attack Russian targets. But sending out official awards to foreign civilians is being seen as a controversial move and a sign of the times. Although many nations, including the UK and the US, have official award systems for ethical hacking, this is thought to be the first time a country has awarded hackers for malicious and possibly criminal hacks. In October, in response to the increase in vigilante hacking in Ukraine and in the Gaza conflict, the International Committee of the Red Cross (ICRC) warned against the use and encouragement of civilian hackers. It published guidelines to reinforce the ethos of the rules of war laid out in the existing Geneva Conventions. Dr Lukasz Olejnik, author of Philosophy of Cyber-security, said Ukraine's awards to foreign hackers are potentially problematic. ""Giving out awards may further blur the lines between combatants and civilians, and even undermine the recent call by the ICRC to limit and end the involvement of civilians in combat operations. In the long run, such an erosion is dangerous,"" he said. Dr Olejnik also said it is a ""testament of our times"" that cyber is now considered as a domain of operations and that anyone can join the fight online. Kristopher started hacking Russia when it launched the full-scale invasion in February 2022, and says he has devoted himself to the cause and sacrificed a lot. ""I've lost my job doing this and spent all my life savings in pursuit of a victory for Ukraine,"" he said from his home office. ""This award is a real morale-booster,"" he said. The awards do not state which cyber-attacks were most useful, but Voltage has three in mind as the most likely candidates. At the start of the invasion in 2022, One Fist spent months mapping out the physical and cyber-locations of hundreds of publicly viewable CCTV cameras in Ukraine. It was discovered that Russian forces were using them to monitor troops, so his team helped get the cameras switched off. Conversely, it was One Fist that hacked into cameras in occupied Crimea to catalogue Russian tanks and equipment being moved over the Kerch bridge. And most recently, in January, Kristopher and others also successfully hacked into a prominent Russian weapons-maker and stole 100 gigabytes of private data, which led to a public celebration from the Ukrainian authorities. ""The array of information transferred to the Ministry of Defence of Ukraine contains drawings, specifications, patents, software referring to both existing and promising military developments,"" the announcement said. Ukraine added that the data stolen was a ""significant blow"" to Moscow and worth $1.5bn (£1.2bn) - although it did not say how this figure was reached The Ukraine conflict prompted a surge of cyber-activity - mostly from supporters of Ukraine. Groups like the Anonymous collective targeted Russia with disruptive and low-level hacks that Russia largely brushed off. In some instances, TV and radio stations were hijacked and news websites defaced. Russian authorities too have been accused of working with vigilante hacking groups like Killnet to attack Ukraine, but has never admitted having any relationship to the gangs. Most of the vigilante hacking activity on both sides dissipated after the first year as the war ground on. But One Fist has kept attacking Russia and increasingly worked closely with the Ukrainian forces on choosing targets. Emily Taylor, chief executive of Oxford Information Labs and editor of Chatham House Cyber Policy journal, agrees that the hacking awards are a landmark moment that might shift thinking about how cyber volunteers are used in conflicts. ""Governments usually discourage non-state actors from taking direct action in the cyber-domain, for fear of escalation or unintended consequences, but wartime is often a period of extraordinary technological innovation, and the Ukraine invasion is no exception,"" she said. ""Sometimes these events force a reconsideration of issues that have previously been taboo."" Kristopher says his team has built up a strong relationship with the Ukrainian military. ""They send us ideas and we send them options but they don't ever give us any help or funding as I think that would cross some sort of line,"" he said. Kristopher recognises that receiving military awards is controversial, but is determined to keep hacking for Ukraine. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," A team of vigilante hackers carrying out cyber-attacks against Russia has been sent awards of gratitude by Ukraine's military. The team, One Fist, has stolen data from Russian military firms and hacked cameras to spy on troops. Since the start of the conflict, Ukraine has controversially been encouraging volunteer hackers to attack Russian targets. Although many nations, including the UK and the US, have official award systems for ethical hacking, this is thought to be the first time a country has awarded hackers for malicious and possibly criminal hacks. In October, in response to the increase in vigilante hacking in Ukraine and in the Gaza conflict, the International Committee of the Red Cross (ICRC) warned against the use and encouragement of civilian hackers. Dr Lukasz Olejnik, author of Philosophy of Cyber-security, said Ukraine's awards to foreign hackers are potentially problematic."
206,Billie Eilish and Nicki Minaj want stop to 'predatory' AI,https://www.bbc.com/news/technology-68717863,https://ichef.bbci.co.uk/news/480/cpsprodpb/15BEA/production/_133066098_mediaitem133028540.jpg.webp,2 Apr 2024,"In an open letter, also signed by Katy Perry, the artists said AI was being used to steal their voices.","Billie Eilish and Nicki Minaj are among 200 artists calling for the ""predatory"" use of artificial intelligence (AI) in the music industry to be stopped. In an open letter also signed by Katy Perry and the estate of Frank Sinatra, they warn AI ""will set in motion a race to the bottom"" if left unchecked. Tech giants including YouTube have tested AI music-making tools. ""We must protect against the predatory use of AI to steal artists' voices and likenesses,"" they said. They have called on tech firms to pledge not to develop AI music-generation tools ""that undermine or replace the human artistry of songwriters and artists, or deny us fair compensation for our work"". In an open letter organised by campaign group the Artists' Rights Alliance and posted on long-form writing site Medium, the artists say AI will ""infringe upon our rights and devalue the rights of human artists"" if it is used irresponsibly. They said the way that artists' work is used to train some AI models and systems was ""an assault on human creativity"", and warned it was being used to ""violate creators' rights, and destroy the music ecosystem"". Tom Kiehl, interim head of industry association UK Music, said he shared the concerns of artists who worry their work is being used to train AI without their permission. ""This amounts to music laundering and any companies engaged in these practices must stop and take a more responsible approach to our music industry,"" he said. ""Ensuring artists have given their consent and receive appropriate credit and compensation for the use of their work on AI systems must be the foundation to a more responsible approach."" Artists spanning creative disciplines and genres have spoken out about how AI is used in recent months, after a song which used AI to mimic the voices of Drake and The Weeknd went viral online. Drake voiced disapproval over the song which sounded a lot like him - but was in fact generated using AI voice cloning tools - and appeared on Spotify and Apple Music before being abruptly pulled down. Other artists have since spoken out about it, with Sting telling the BBC he believes musicians face ""a battle"" to defend their work against the rise of songs written by AI. ""The building blocks of music belong to us, to human beings,"" he said. But not all musicians oppose developments in or use of AI across the music industry, and electronic artist Grimes and DJ David Guetta are among those backing the use of such AI tools. Grimes has even encouraged fans and budding musicians to use her voice ""without penalty"" and said she would split royalties on successful AI-generated tracks using her voice. The BBC has approached Google, which owns YouTube, for comment. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," ""We must protect against the predatory use of AI to steal artists' voices and likenesses,"" they said. They have called on tech firms to pledge not to develop AI music-generation tools ""that undermine or replace the human artistry of songwriters and artists, or deny us fair compensation for our work"". In an open letter organised by campaign group the Artists' Rights Alliance and posted on long-form writing site Medium, the artists say AI will ""infringe upon our rights and devalue the rights of human artists"" if it is used irresponsibly. They said the way that artists' work is used to train some AI models and systems was ""an assault on human creativity"", and warned it was being used to ""violate creators' rights, and destroy the music ecosystem""."
207,UK and US sign landmark deal to test AI safety,https://www.bbc.com/news/technology-68675654,https://ichef.bbci.co.uk/news/480/cpsprodpb/16A86/production/_133060829_mediaitem133060828.jpg.webp,2 Apr 2024,The new agreement will see the countries pool knowledge and resources to strengthen safety testing of AI models,"The UK and US have signed a landmark deal to work together on testing advanced artificial intelligence (AI). The agreement signed on Monday says both countries will work together on developing ""robust"" methods for evaluating the safety of AI tools and the systems that underpin them. It is the first bilateral agreement of its kind. UK tech minister Michelle Donelan said it is ""the defining technology challenge of our generation"". ""We have always been clear that ensuring the safe development of AI is a shared global issue,"" she said. ""Only by working together can we address the technology's risks head on and harness its enormous potential to help us all live easier and healthier lives."" The secretary of state for science, innovation and technology added that the agreement builds upon commitments made at the AI Safety Summit held in Bletchley Park in November 2023. The event, attended by AI bosses including OpenAI's Sam Altman, Google DeepMind's Demis Hassabis and tech billionaire Elon Musk, saw both the UK and US create AI Safety Institutes which aim to evaluate open and closed-source AI systems. While things have felt quiet on the AI safety front since the summit, the AI sector itself has been extremely busy. Competition between the biggest AI chatbots - such as ChatGPT, Gemini, Claude - remains ferocious. So far the almost exclusively US-based firms behind all of this activity are still cooperating with the concept of regulation, but regulators have yet to curtail anything these companies are trying to achieve. Similarly, regulators have not demanded access to information the AI firms are unwilling to share, such as the data used to train their tools orthe environmental cost of running them. TheEU's AI Act is on its way to becoming law and once it takes effect it will require developers of certain AI systems to be upfront about their risks and share information about data used. This is important, after OpenAIrecently saidit would not release a voice cloning tool it developed due to ""serious risks"" the tech presents, particularly in an election year. In January, a fake, AI-generated robocall claiming to be from US President Joe Biden urged voters to skip a primary election in New Hampshire. Currently in the US and UK, AI firms are mostly regulating themselves. Currently, the majority of AI systems are only capable of performing single, intelligent tasks that would usually be completed by a human. Known as ""narrow"" AI, these tasks can range from quickly analysing data or providing a desired response to a prompt. But there are fears that more intelligent ""general"" AI tools - capable of completing a range of tasks usually performed by humans - could endanger humanity. ""AI, like chemical science, nuclear science, and biological science, can be weaponised and used for good or ill,"" Prof Sir Nigel Shadbolt told the BBC's Today programme. But the University of Oxford professor said fears around AI's existential risk ""are sometimes a bit overblown"". ""We've got to be really supportive and appreciative of efforts to get great AI powers thinking about and researching what the dangers are,"" he said. ""We need to understand just how susceptible these models are, and also how powerful they are."" Gina Raimondo, the US commerce secretary, said the agreement will give the governments a better understanding of AI systems, which will allow them to give better guidance. ""It will accelerate both of our Institutes' work across the full spectrum of risks, whether to our national security or to our broader society,"" she said. ""Our partnership makes clear that we aren't running away from these concerns - we're running at them."" Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," The secretary of state for science, innovation and technology added that the agreement builds upon commitments made at the AI Safety Summit held in Bletchley Park in November 2023. The event, attended by AI bosses including OpenAI's Sam Altman, Google DeepMind's Demis Hassabis and tech billionaire Elon Musk, saw both the UK and US create AI Safety Institutes which aim to evaluate open and closed-source AI systems. So far the almost exclusively US-based firms behind all of this activity are still cooperating with the concept of regulation, but regulators have yet to curtail anything these companies are trying to achieve. Similarly, regulators have not demanded access to information the AI firms are unwilling to share, such as the data used to train their tools orthe environmental cost of running them."
208,Temu U-turns on terms of cash 'giveaway' offer,https://www.bbc.com/news/technology-68675652,https://ichef.bbci.co.uk/news/480/cpsprodpb/DB3C/production/_133042165_gettyimages-1507823481.jpg.webp,29 Mar 2024,The retailer changes what it can do with customer data after privacy concerns were raised.,"Chinese e-retailer Temu has significantly changed the terms of a cash giveaway after customers expressed concerns. Participants in the promotion - which has gone viral on social media - receive up to £50, but had to agree to permanently hand over considerable amounts of personal data. Previously, Temu had said these were ""standard terms and conditions"". But now it says it has ""tweaked"" those terms because they were ""overly broad"". Data watchdog the Information Commissioner's Office, which had been looking into concerns about Temu's offer, said it would ""continue to consider the concerns raised"". The Chinese-owned online marketplace launched in the US in 2022 and the UK last year. It has been described as ""Amazon on steroids"" by retail experts and is known for selling goods at extremely cheap prices, using the slogan ""shop like a billionaire"". But it has faced criticism from politicians, with a US government investigation finding an ""extremely high risk"" that products on Temu could have been made with forced labour. The firm's giveaway gives new users 24 hours to sign up other people using a shareable link so each receive a cash reward of between £40 and £50 - paid to their PayPal accounts - or in Temu store credit. Existing Temu account holders can also participate, but appear to have to reach a higher threshold for such rewards. Thousands of users eager to cash in on the promotion have been seen posting links across social media sites. But it has also been the subject of memes and posts scrutinising the rules. The section receiving the most scrutiny states that ""except to the extent prohibited by applicable law"", participants give the company consent to use and publish their ""photo, name, likeness, voice, opinions, statements, biographical information, and/or hometown and state"" for advertising or promotional purposes. It adds this can take place in any media worldwide and ""in perpetuity"" - meaning with no fixed end date. One such post on X (formerly Twitter) with screengrabs of the campaign's usage and publicity rules has been viewed more than two million times, according to the platform's metrics. A number of other X users claimed the rules would allow Temu to sell their data or even create deepfake adverts - though those claims were strenuously denied by the retailer. But now, the fast growing, Chinese-owned retailer has changed those rules, saying ""some participants"" in the cash offer had ""expressed concern"". It said it had ""tweaked"" the terms and conditions ""to make it clear that we only ever use username and profile pictures in this promotion for referral functionality and winner announcements"". ""The previous terms and conditions were overly broad and inadvertently included promotional uses that Temu does not engage in,"" it added. ""Customer trust and satisfaction is at the heart of Temu, and we do not and will not sell customer data."" This is a U-turn compared with previous statements from the company. Previously, a Temu spokesperson had said giveaways were commonplace across many firms and different industries, and cited its e-commerce rival Shein as an example of a firm running promotions with ""nearly identical terms and conditions"". ""If these standard terms and conditions for run-of-the-mill promotional activities are newsworthy, then we urge you to be fair and report on their use by other companies instead of singling out Temu,"" the spokesperson had said. Experts had also raised concerns about the terms of the promotion. ""Giving away permission for Temu to use your 'voice' and 'biographical information' will understandably concern its customers,"" said Lisa Webb, Which? consumer law expert. ""These offers are going viral on social media, including to young people, but consumers should definitely consider whether they are comfortable giving this sensitive data away in return for cash."" She had added that ""while Temu isn't the first platform to excessively hoover up data, there are definite question marks over whether requesting permission for personal data to be used 'worldwide' is proportionate in any circumstances"". Jonathan Kirsop, data protection partner at law firm Pinsent Mason, had told BBC News it was not a wording he had seen used commonly before and the activity implied may have been ""problematic"". The previous terms could have fallen foul of UK data protection rules, which require user consent to be freely given, specific and able to be withdrawn in order for it to be relied upon as a reason for data processing. ""While not always prohibited, making the provision of services conditional on a consent to the use of personal data will often be unlawful on the basis the user may not be considered to have a free choice in delivering that consent, particularly where the data concerned is sensitive, such as biometric data,"" he said. The use of voice data - which is considered biometric data under the UK's General Data Protection Regulation (GDPR) - has a higher threshold for lawful use and consent in the UK because it carries greater risks, he added. The data regulator, the Information Commissioner's Office, had previously said it was ""aware of reports about Temu"" and was ""considering the concerns raised."" In a fresh comment, made after Temu altered the terms and conditions, the data watchdog said: ""Organisations must be clear and transparent about how and why they collect and use people's personal information, and ensure people can make a fully informed decision as to whether to hand over their data."" ""We are aware of reports about Temu, and subsequent updates to the terms and conditions, and continue to consider the concerns raised."" Awais Rashid, professor of cyber security at the University of Bristol, had told BBC News that apps collecting a lot of data - often more than they actually need from users - had become commonplace. He said this, as well as cash incentives or long, sometimes ""indecipherable"" privacy policies and terms, can make the decision more difficult and imbalanced when deciding whether or not we as individuals should part with our data to use a service. ""Whenever there is such a deal being offered we must always look at: what is the consequence of this, and how much of our data is going to be collected, how it is going to be used, and are we comfortable with that?"" he said. Have you signed up to this offer from Temu? Share your thoughts by emailing haveyoursay@bbc.co.uk. Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways: If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission. Copyright 2024 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.  "," Participants in the promotion - which has gone viral on social media - receive up to £50, but had to agree to permanently hand over considerable amounts of personal data. Previously, Temu had said these were ""standard terms and conditions"". Data watchdog the Information Commissioner's Office, which had been looking into concerns about Temu's offer, said it would ""continue to consider the concerns raised"". The section receiving the most scrutiny states that ""except to the extent prohibited by applicable law"", participants give the company consent to use and publish their ""photo, name, likeness, voice, opinions, statements, biographical information, and/or hometown and state"" for advertising or promotional purposes. ""The previous terms and conditions were overly broad and inadvertently included promotional uses that Temu does not engage in,"" it added."
